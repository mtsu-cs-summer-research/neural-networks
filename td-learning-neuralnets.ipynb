{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD Learning Using Neural Networks\n",
    "\n",
    "In this notebook, we will perform TD Learning on a one dimensional maze very similarly to the previous TD Learning notebook. However, we will no longer be using a table. Rather, we will replace this table with a neural network. Since neural networks can approximate functions, we will use one to approximate the table that would be used otherwise. With small, simple mazes, the benefits may not be immediately recognizable. However with more complex scenarios, this can save a great amount of space. There is an added benefit of not having to deal with complex tables.\n",
    "\n",
    "We will be using _Holographic Reduced Representations_ to encode information for the neural network. This is able to represent the states of the maze, as well as things such as colored signals, and allow them to be combined in meaninful ways. The following class written by Dr. Phillips produces these _HRR_'s:\n",
    "\n",
    "##### HRR Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load hrr.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import numpy\n",
    "import shelve\n",
    "import os\n",
    "import glob\n",
    "import gc\n",
    "import itertools\n",
    "\n",
    "def hrr(length,normalized=False):\n",
    "    \"Creates Holographic Reduced Representations\"\n",
    "\n",
    "    if normalized:\n",
    "        x = numpy.random.uniform(-numpy.pi,numpy.pi,int((length-1)/2))\n",
    "        if length % 2:\n",
    "            x = numpy.real(numpy.fft.ifft(numpy.concatenate([numpy.ones(1),numpy.exp(1j*x),numpy.exp(-1j*x[::-1])])))\n",
    "        else:\n",
    "            x = numpy.real(numpy.fft.ifft(numpy.concatenate([numpy.ones(1),numpy.exp(1j*x),numpy.ones(1),numpy.exp(-1j*x[::-1])])))\n",
    "    else:\n",
    "        x = numpy.random.normal(0.0,1.0/numpy.sqrt(length),length)\n",
    "        \n",
    "    return x\n",
    "\n",
    "def hrri(length):\n",
    "    \"Returns the identity vector for N-length HRRs.\"\n",
    "    return numpy.concatenate([numpy.ones(1),numpy.zeros(length-1)])\n",
    "\n",
    "def hrrs(length,n=1,normalized=False):\n",
    "    \"Creates a matrix of n HRRs, one per row.\"\n",
    "    return numpy.row_stack([hrr(length,normalized) for x in range(n)])\n",
    "\n",
    "def inv(x):\n",
    "    \"Computes the -exact- inverse of an HRR.\"\n",
    "    x = numpy.fft.fft(x)\n",
    "    return numpy.real(numpy.fft.ifft((1.0/numpy.abs(x))*numpy.exp(-1j*numpy.angle(x))))\n",
    "\n",
    "def pinv(x):\n",
    "    \"Computes the pseudo-inverse of an HRR.\"\n",
    "    return numpy.real(numpy.fft.ifft(numpy.conj(numpy.fft.fft(x))))\n",
    "\n",
    "def convolve(x,y):\n",
    "    \"Computes the circular convolution of two HRRs.\"\n",
    "    return numpy.real(numpy.fft.ifft(numpy.fft.fft(x)*numpy.fft.fft(y)))\n",
    "\n",
    "def mconvolve(x):\n",
    "    \"Computes the circular convolution of a matrix of HRRs.\"\n",
    "    return numpy.real(numpy.fft.ifft(numpy.apply_along_axis(numpy.prod,0,numpy.apply_along_axis(numpy.fft.fft,1,x))))\n",
    "    \n",
    "def oconvolve(x,y):\n",
    "    \"Computes the convolution of all pairs of HRRs in the x and y matrices.\"\n",
    "    return numpy.row_stack([ [convolve(x[i,:],y[j,:]) for i in range(x.shape[0]) ] for j in range(y.shape[0]) ])\n",
    "\n",
    "def correlate(x,y,invf=pinv):\n",
    "    \"Computes the correlation of the two provided HRRs.\"\n",
    "    return convolve(x,invf(y))\n",
    "\n",
    "def compose(x,y):\n",
    "    \"Composes two HRRs using addition in angle space. (in-progress)\"\n",
    "    x = numpy.fft.fft(x)\n",
    "    y = numpy.fft.fft(y)\n",
    "    return numpy.real(numpy.fft.ifft((x+y)/2.0))\n",
    "\n",
    "def mcompose(x):\n",
    "    \"Composes a matrix of HRRs, one per row, using addition in angle space. (in-progress)\"\n",
    "    x = numpy.apply_along_axis(numpy.fft.fft,1,x)\n",
    "    return numpy.real(numpy.fft.ifft(numpy.apply_along_axis(numpy.mean,0,x)))\n",
    "\n",
    "def decompose(x,y):\n",
    "    \"Decomposes two HRRs using addition in angle space. (in-progress)\"\n",
    "    return compose(x,-y)\n",
    "\n",
    "def pow(x,k):\n",
    "    \"Compute the convolutive power of an HRR.\"\n",
    "    ## Original method only allowed for unitary vectors to\n",
    "    ## have convolutive powers since magnitudes could not\n",
    "    ## be kept in check for non-unitary vectors...\n",
    "    ## return numpy.real(numpy.fft.ifft(numpy.power(numpy.fft.fft(x),k)))\n",
    "    ## New version, allows for non-unitary vectors to\n",
    "    ## have convolutive powers, but there is still an\n",
    "    ## inversion problem since x and sqrt(x^2) are not\n",
    "    ## the same vector...\n",
    "    x = numpy.fft.fft(x)\n",
    "    return numpy.real(numpy.fft.ifft(numpy.abs(x)*numpy.exp(1j*numpy.angle(numpy.power(x,k)))))\n",
    "\n",
    "class LTM:\n",
    "    \"Long-term Memory\"\n",
    "    store = None\n",
    "    ## Note - this is linux-specific\n",
    "    tmpdir = \"/dev/shm/\"\n",
    "    ## Might want to choose something else in the future...\n",
    "    \n",
    "    ## Default HRR size\n",
    "    N = 1024\n",
    "    normalized = False\n",
    "    \n",
    "    def __init__(self,N=1024,normalized=False):\n",
    "        self.store = shelve.open(self.tmpdir + \"hrr_ltm_\" + str(os.getpid()) + \"_\" + str(id(self)))\n",
    "        self.N = N\n",
    "        self.normalized = normalized\n",
    "        self.store[\"\"] = hrri(self.N)\n",
    "        \n",
    "    def __del__(self):\n",
    "        if (self.store is not None):\n",
    "            self.store.close()\n",
    "            for f in glob.glob(self.tmpdir + \"hrr_ltm_\" + str(os.getpid()) + \"_\" + str(id(self)) + \".*\"):\n",
    "                os.remove(f)\n",
    "                \n",
    "    def lookup(self,q):\n",
    "        \"Lookup a single symbol, encode it if necessary\"\n",
    "        if q in self.store:\n",
    "            return self.store[q]\n",
    "        else:\n",
    "            self.store[q] = hrr(self.N,self.normalized)\n",
    "            return self.store[q]\n",
    "    \n",
    "    def encode(self,q):\n",
    "        \"Encode an HRR\"\n",
    "        if not isinstance(q,str):\n",
    "            return None\n",
    "        q = q.split('+')\n",
    "        rep = numpy.zeros(self.N)\n",
    "        for substr in q:\n",
    "            substr = sorted(substr.split('*'))\n",
    "            key = '*'.join(substr)\n",
    "            if key not in self.store:\n",
    "                ## Base concepts\n",
    "                for i in range(len(substr)):\n",
    "                    self.lookup(substr[i])\n",
    "                ## Combinatorix\n",
    "                for L in range(1,len(substr)):\n",
    "                    for combination in itertools.combinations(substr,L+1):\n",
    "                        key = '*'.join(sorted(combination))\n",
    "                        print(key)\n",
    "                        if key not in self.store:\n",
    "                            subrep = hrri(self.N)\n",
    "                            for i in range(len(combination)):\n",
    "                                subrep = convolve(subrep,self.lookup(combination[i]))\n",
    "                            self.store[key] = subrep\n",
    "            rep += self.store[key]\n",
    "        rep /= numpy.sqrt(len(q))\n",
    "        return rep\n",
    "    \n",
    "    def decode(self,q):\n",
    "        \"Find closest match currently in memory.\"\n",
    "        if isinstance(q,str):\n",
    "            return None\n",
    "        match = None\n",
    "        best = -numpy.inf\n",
    "        for key in self.store.keys():\n",
    "            if numpy.dot(q,self.store[key]) > best:\n",
    "                best = numpy.dot(q,self.store[key])\n",
    "                match = key\n",
    "        return match\n",
    "    \n",
    "    def unpack(self,q):\n",
    "        \"Unpack all possible symbols and subsymbols\"\n",
    "        if not isinstance(q,str):\n",
    "            return None\n",
    "        q = str.split(q.lower(),'+')\n",
    "        reps = dict()\n",
    "        for substr in q:\n",
    "            substr = sorted(substr.split('*'))\n",
    "            for L in range(len(substr)):\n",
    "                for combination in itertools.combinations(substr,L+1):\n",
    "                    key = '*'.join(sorted(combination))\n",
    "                    reps[key] = self.encode(key)\n",
    "        return reps\n",
    "\n",
    "    def print(self):\n",
    "        print(self)\n",
    "        for key in self.store.keys():\n",
    "            print(key,self.store[key])\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Maze Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from fractions import Fraction\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "\n",
    "LENGTH = 6  # Try me out\n",
    "HRRLEN = 64\n",
    "GAMMA = .5\n",
    "GOAL = 0\n",
    "EPOCH = 300\n",
    "\n",
    "class Maze:\n",
    "    def __init__(self):\n",
    "        # Initialize reward vector\n",
    "        self._reward = np.zeros(LENGTH)  # Reward Vector\n",
    "        self._reward[GOAL] = 1\n",
    "        \n",
    "        # Initialize holographic reduced representations\n",
    "        self.states = hrrs(HRRLEN, LENGTH, normalized=True)\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = keras.Sequential()\n",
    "        self.model.add(keras.layers.Dense(1,\n",
    "                                          activation=None,\n",
    "                                          input_dim=HRRLEN))\n",
    "        self.model.compile(loss=keras.losses.mse,\n",
    "                           optimizer=keras.optimizers.SGD(lr=0.1))\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    # Disply the maze with current values inside\n",
    "    def display(self):\n",
    "        # obtain values for all states from model\n",
    "        values = self.model.predict(self.states)\n",
    "        \n",
    "        # top of maze\n",
    "        print(\" --------\" * LENGTH)\n",
    "        \n",
    "        print(\"|\", end='')\n",
    "        \n",
    "        # print each predicted value\n",
    "        for i in range(LENGTH):\n",
    "            number = np.round(values[i],4)\n",
    "            print(\"{:^8.4f}|\".format(number[0]), end='')\n",
    "        print()\n",
    "        \n",
    "        # bottom of maze\n",
    "        print(\" --------\" * LENGTH)\n",
    "        for i in range(LENGTH):\n",
    "            print(\"   \", i, \"   \", end='')\n",
    "        print()\n",
    "        return\n",
    "\n",
    "    # Drop agent into maze and search for goal\n",
    "    def episode(self, s):\n",
    "        # Search and update value until reaches goal\n",
    "        while(s != GOAL):  \n",
    "            # calculate delta and update model\n",
    "            self.delta(s)\n",
    "            # next state\n",
    "            values = self.model.predict(np.array(self.states))\n",
    "            s = self.nextS(s, values)\n",
    "        \n",
    "        # calculate delta for goal\n",
    "        self.delta(s)\n",
    "        return\n",
    "    \n",
    "    # model updated within function\n",
    "    # delta(s) = (r(s) + gamma v(s + 1)) - v(s)\n",
    "    def delta(self, s):\n",
    "        # if the state is the goal, train it to equal reward value\n",
    "        if (s == GOAL):\n",
    "            state = np.array([self.states[GOAL]])\n",
    "            self.model.fit(state, [self._reward[GOAL]],\n",
    "                           batch_size=1,\n",
    "                           epochs=1,\n",
    "                           verbose=0)\n",
    "        # otherwise, train it to equal the target value\n",
    "        else:\n",
    "            values = self.model.predict(self.states)\n",
    "            nextS = self.nextS(s, values)\n",
    "            target = GAMMA * values[nextS][0]\n",
    "            self.model.fit(np.array([self.states[s]]),\n",
    "                           [target],\n",
    "                           batch_size=1,\n",
    "                           epochs=1,\n",
    "                           verbose=0)\n",
    "            \n",
    "    # Obtain the value of a state\n",
    "    # v(s) = r(s) + GAMMA * v(s+1)\n",
    "    def v(self, s, values):\n",
    "        # to determine the value, function needs to look\n",
    "        #    at (s + 1).\n",
    "        \n",
    "        # determine left and right values (accounting for wrap around)\n",
    "        if (s == 0):\n",
    "            left = (LENGTH-1)\n",
    "            right = s + 1\n",
    "        elif (s == (LENGTH-1)):\n",
    "            left = s - 1\n",
    "            right = 0\n",
    "        else:\n",
    "            left = s - 1\n",
    "            right = s + 1\n",
    "        \n",
    "        # determine direction\n",
    "        if (values[left][0] >= values[right][0]):\n",
    "            nextS = left\n",
    "        else:\n",
    "            nextS = right\n",
    "        \n",
    "        # v(s) = r(s) + GAMMA * v(s+1)\n",
    "        return self._reward[s] + GAMMA * values[nextS][0]\n",
    "            \n",
    "\n",
    "    # Obtain the next state to be moved to (s + 1)\n",
    "    def nextS(self, s, values):\n",
    "        # determine left and right values (accounting for wrap around)\n",
    "        if (s == 0):\n",
    "            left = (LENGTH-1)\n",
    "            right = s + 1\n",
    "        elif (s == (LENGTH-1)):\n",
    "            left = s - 1\n",
    "            right = 0\n",
    "        else:\n",
    "            left = s - 1\n",
    "            right = s + 1\n",
    "            \n",
    "        # determine direction\n",
    "        if (self.v(left, values) >= self.v(right, values)):\n",
    "            nextS = left\n",
    "        else:\n",
    "            nextS = right\n",
    "        return nextS\n",
    "    \n",
    "    # Obtain the matrix of state values\n",
    "    def get_values(self):\n",
    "        values = self.model.predict(self.states)\n",
    "        values = np.reshape(values, (LENGTH))\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maze before training:\n",
      " -------- -------- -------- -------- -------- --------\n",
      "|-0.0289 | 0.0958 | 0.1883 |-0.0774 | 0.1379 |-0.1905 |\n",
      " -------- -------- -------- -------- -------- --------\n",
      "    0        1        2        3        4        5    \n",
      "Maze after training:\n",
      " -------- -------- -------- -------- -------- --------\n",
      "| 1.0000 | 0.5000 | 0.2500 | 0.1250 | 0.2500 | 0.5000 |\n",
      " -------- -------- -------- -------- -------- --------\n",
      "    0        1        2        3        4        5    \n"
     ]
    }
   ],
   "source": [
    "maze = Maze()\n",
    "print(\"Maze before training:\")\n",
    "maze.display()\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    s = np.random.randint(0, LENGTH)\n",
    "    maze.episode(s)\n",
    "\n",
    "print(\"Maze after training:\")\n",
    "maze.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
