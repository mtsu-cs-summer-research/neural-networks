{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Maze with Q Learning\n",
    "\n",
    "In this notebook we attempt to solve the 1D Maze reinforcement learning problem. However, instead of using _TD Learning_ we will be using _Q Learning_. The difference is in the value function and the delta function. When using Q learning, one considers the value of a __state action pair__. Being in a state and going left has a different value than being in a state and going right. The Q function and delta function look like so: <br>\n",
    "$\\boldsymbol{Q}(\\boldsymbol{s},\\boldsymbol{a}) = \\boldsymbol{r}(\\boldsymbol{s} + 1) + \\gamma \\boldsymbol{r}(\\boldsymbol{s} + 2) \\ldots \\gamma^{\\boldsymbol{n}-1} \\boldsymbol{r}(\\boldsymbol{s}+\\boldsymbol{n})$ <br>\n",
    "$\\delta(\\boldsymbol{s},\\boldsymbol{a}) = (\\boldsymbol{r}(\\boldsymbol{s}+1) + \\gamma \\boldsymbol{Q}(\\boldsymbol{s}+1, \\boldsymbol{a}+1)) - \\boldsymbol{Q}(\\boldsymbol{s}, \\boldsymbol{a})$ <br>\n",
    "\n",
    "The Q Table for a maze of length four would look like the following:\n",
    "\n",
    "| State: | 1 | 2 | 3 | 4 |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Left | 1/2 | 1 | 1/2 | 1/4 |\n",
    "| Right | 1/2 | 1/4 | 1/2 | 1 |\n",
    "\n",
    "__Warning: This code is not yet functional__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sympy import *\n",
    "init_printing(use_latex=True)\n",
    "from fractions import Fraction\n",
    "\n",
    "EPOCH = 20\n",
    "GAMMA = .5\n",
    "class Maze:\n",
    "    def __init__(self, goal, length):\n",
    "        self.reward = np.zeros(length)\n",
    "        self.value = np.zeros((2,length))\n",
    "        self.goal = goal\n",
    "        self.length = length\n",
    "        \n",
    "        self.reward[goal] = 1\n",
    "        \n",
    "    # Performs one episode of learning on the maze\n",
    "    # S is the starting state\n",
    "    def episode(self, s):\n",
    "        a = 0   # Must select an action to start with\n",
    "        while s != self.goal:\n",
    "            self.value[a, s] += self.delta(s,a)\n",
    "            s, a = self.nextS(s, a)\n",
    "    \n",
    "    # delta(s,a) = r(s+1) + GAMMA * maxQ(s+1,a+1) - Q(s,a)\n",
    "    def delta(self, s, a):\n",
    "        # Obtain what the next state will be and the value\n",
    "        \n",
    "        return self.Q(s, a) - self.value[a,s]\n",
    "    \n",
    "    # Q(s,a) = r(s+1) + GAMMA * Q(s+1, a+1)\n",
    "    def Q(self, s, a):\n",
    "        nextS, nextA = self.nextS(s, a)\n",
    "        future_value = self.reward[nextS] + GAMMA * self.value[nextA,nextS]\n",
    "        return future_value\n",
    "        \n",
    "    # Determine which state is next\n",
    "    def nextS(self, s, a):\n",
    "        # Obtain which state is to the left and which is to the right\n",
    "        if (s == 0):\n",
    "            left = self.length-1\n",
    "            right = s+1\n",
    "        elif (s == self.length-1):\n",
    "            left = s-1\n",
    "            right = 0\n",
    "        else:\n",
    "            left = s-1\n",
    "            right = s+1\n",
    "        # Execute the action\n",
    "        if (a == 0):\n",
    "            nextS = left\n",
    "        else:\n",
    "            nextS = right\n",
    "        \n",
    "        # Which action will have the highest value?\n",
    "        if (self.value[0, nextS] >= self.value[1, nextS]):\n",
    "            nextA = 0\n",
    "        else:\n",
    "            nextA = 1\n",
    "        return nextS, nextA\n",
    "    \n",
    "    # Print the maze \n",
    "    def display(self):\n",
    "        print(\"The value matrix is:\")\n",
    "        print(\"L: \", end='')\n",
    "        for i in self.value[0]:\n",
    "            print( \"|\", Fraction(i), end='')\n",
    "        print(\"|\")\n",
    "        print(\"R: \", end='')\n",
    "        for i in self.value[1]:\n",
    "            print( \"|\", Fraction(i), end='')\n",
    "        print(\"|\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value matrix is:\n",
      "L: | 0| 0| 0| 0| 0| 0|\n",
      "R: | 0| 0| 0| 0| 0| 0|\n",
      "The value matrix is:\n",
      "L: | 0| 1| 1/2| 1/4| 1/8| 1/16|\n",
      "R: | 0| 0| 0| 0| 0| 0|\n"
     ]
    }
   ],
   "source": [
    "maze = Maze(0, 6)\n",
    "maze.display()\n",
    "for i in range(EPOCH):\n",
    "    s = np.random.randint(0, maze.length)\n",
    "    maze.episode(s)\n",
    "    \n",
    "maze.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEcAAAASCAYAAAAJ88NbAAAABHNCSVQICAgIfAhkiAAAAydJREFUWIXt102oVVUUB/BfZZlGPPuyNzB68cgK+hiIVoaKRQZJkX1QAy2iggalRpgQBM+ZiEjhoJpk0KBBlDip7DupRsEbKJYWeI2wV2oqmtZLew3WPng69+x377GXTd4fDvvetdf+73XW2Xv992YcjTANr2EP/kALL+KC08R1GzZiKI3Zg824s+J3ER5Pvt/jGA7hCzyGMzP8LYxknqGy4xmVgf34ClOxCd9iFuZjB27B/lFe7N9yrcEK/Ij3sA+XYAY+wnMl3yfxMn7Cp/gBl+Je9OBtPJBeuowWpoiPVMURrM290OZE9nTFvi7ZX8kNHAOuJ5L9dZxTw3d25f+tuEv7CukViRrBfTU8rfQ0Qn8i3FUz4fkiq7/hvP+AayJ+wW71iWmK59P862v6WrpMTjnw+an9AH9V/A7jS0zGTV3wNuW6XWyfd5L/QqzEMtzcxXxV/Jna45n+iVgskrgsxXtW1WlC6fdVqd2ZIfwOCzAdH3cIrinXzGT/HYO4tuK/Bfdjb4d5iXd6OP1+P+PTizcqtl14FJ8XhvLK6UntoQxhYZ/SRYBNuaamdoXYDnPE9rterL65eKuLeWG1SO67ou5VsUEoYq/Y1tfhVfQJEbihcMzJ3elGEcdx3C3k+Ai2YpFQr3k6b7GleFYo45KMzyp8gp9xFNuE8q3DJAxUg+Lk1+xRj8J+sEOAp8JVtIPai+VRJ1fArFHmfAovYbuoIb92EWcZhXrOLQzl5OxI7fTM4CtTm6sjZTTlKvxziT+Q2kmZ/uVCmbaJxAxl/EZDUc9q1fj/lPLLhUrtrvEnasEIHqzpW5n6BnFxF7HlcEfi2Z5zaHpw68fV2g9op8K1KdmfqdgXiMQd0L5NX0hjvsaFNTFUcY36j9snFHREyDs6Xx++wY1iqe7EbP888rfEV79Ce61oyjUt+V8m5H0w8d6Tgn5IXAkKPCJO0yfElqpTxlbyKTAgCvYWsUoPpzgX4lyhcIswXMNFCm6DuLMMJ5LcZbGVAu8bAy7iILg++Q2Lu9VG9YV4QP4CWTyfVcbMw5tCzQ6Kw+JefCjORtXFMo5xjGNs8TdVz/ilidpKrAAAAABJRU5ErkJggg==\n",
      "text/latex": [
       "$$0.0625$$"
      ],
      "text/plain": [
       "0.0625"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maze.delta(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
